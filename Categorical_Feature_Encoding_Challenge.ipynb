{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Categorical Feature Encoding Challenge.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MubleqpgVknn",
        "colab_type": "text"
      },
      "source": [
        "# Is there a cat in your data?\n",
        "Because this is such a common task and important skill to master, we've put together a dataset that contains only categorical features, and includes:\n",
        "\n",
        "binary features\n",
        "low- and high-cardinality nominal features\n",
        "low- and high-cardinality ordinal features\n",
        "(potentially) cyclical features\n",
        "\n",
        "https://www.kaggle.com/alexisbcook/categorical-variables <br>\n",
        "https://towardsdatascience.com/understanding-feature-engineering-part-2-categorical-data-f54324193e63"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "DkTF__7vVkns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9MKru-iVkny",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ARIhEgTMVkn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# basic function of python\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sb\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from pandas import ExcelWriter\n",
        "from pandas import ExcelFile\n",
        "import xlrd\n",
        "from scipy import stats\n",
        "from datetime import datetime\n",
        "\n",
        "# feature hashing\n",
        "from sklearn.feature_extraction import FeatureHasher\n",
        "\n",
        "# target encoder\n",
        "import category_encoders as ce\n",
        "\n",
        "# feature selection\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn import feature_selection\n",
        "\n",
        "# oversampling\n",
        "from sklearn.utils import resample\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# building the models\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "import tensorflow\n",
        "# from tensorflow.contrib.keras import models, layers\n",
        "# from tensorflow.contrib.keras import activations, optimizers, losses\n",
        "\n",
        "# standardize the vaiable\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# from sklearn.cross_validation import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# validation\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyUjEyjfVkn8",
        "colab_type": "text"
      },
      "source": [
        "# Get the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "4_xAnm5DVkn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('../input/cat-in-the-dat/train.csv')\n",
        "test = pd.read_csv('../input/cat-in-the-dat/test.csv')\n",
        "submission = pd.read_csv('../input/cat-in-the-dat/sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bhNvtQdFVkoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YVYkAySaVkoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DeuhkWKyVkoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "THLj_2IiVkoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.drop(['id'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "J6xQs6ZnVkoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.drop(['id'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Q6-2EXCNVkoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['target'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7vb0oqjTVkoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ3WyWnjVkoO",
        "colab_type": "text"
      },
      "source": [
        "# Exploratory Data Analysis\n",
        "In this section, I deal with the data cleaning and check out some missing data or imbalance data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_ulowxcVkoP",
        "colab_type": "text"
      },
      "source": [
        "## Let's check the dimension of dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kXwOfVsxVkoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rpCzzhrpVkoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rFfamYjSVkoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2V5zWgHzVkoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ny8GR3pBVkoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.isnull() # Checking missing values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CjeoEGz4VkoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.isnull().sum() # check the missing values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mXBR4E0FVkoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sb.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZQSCwWbVkob",
        "colab_type": "text"
      },
      "source": [
        "<h4>Evaluating for Missing Data</h4>\n",
        "\n",
        "The missing values are converted to Python's default. We use Python's built-in functions to identify these missing values. There are two methods to detect missing data:\n",
        "<ol>\n",
        "    <li><b>.isnull()</b></li>\n",
        "    <li><b>.notnull()</b></li>\n",
        "</ol>\n",
        "The output is a boolean value indicating whether the value that is passed into the argument is in fact missing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3o3rAAx8Vkob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_data = train.isnull()\n",
        "missing_data.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIeYStuUVkoc",
        "colab_type": "text"
      },
      "source": [
        "<h4>Count missing values in each column</h4>\n",
        "<p>\n",
        "Using a for loop in Python, we can quickly figure out the number of missing values in each column. As mentioned above, \"True\" represents a missing value, \"False\"  means the value is present in the dataset.  In the body of the for loop the method  \".value_counts()\"  counts the number of \"True\" values. \n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zEmGkxH4Vkod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for column in missing_data.columns.values.tolist():\n",
        "    print(column)\n",
        "    print (missing_data[column].value_counts())\n",
        "    print(\"\")    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FxN9jxtWVkoe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.isnull() # Checking missing values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Xjh-CUzuVkof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.isnull().sum() # check the missing values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-clNGOmyVkog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sb.heatmap(test.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ubqhGLhEVkoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_data = test.isnull()\n",
        "missing_data.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaxwJfl3Vkoh",
        "colab_type": "text"
      },
      "source": [
        "<h4>Count missing values in each column</h4>\n",
        "<p>\n",
        "Using a for loop in Python, we can quickly figure out the number of missing values in each column. As mentioned above, \"True\" represents a missing value, \"False\"  means the value is present in the dataset.  In the body of the for loop the method  \".value_counts()\"  counts the number of \"True\" values. \n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "i6SK2Xs3Vkoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for column in missing_data.columns.values.tolist():\n",
        "    print(column)\n",
        "    print (missing_data[column].value_counts())\n",
        "    print(\"\")    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP6EuR_FVkok",
        "colab_type": "text"
      },
      "source": [
        "In conclusion, there is no missing value in this dataset. We don't need to handle the missing value:)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3djiQiyFVkok",
        "colab_type": "text"
      },
      "source": [
        "# Converting Categorical Features\n",
        "We'll need to convert categorical features to numerical features. Otherwise our machine learning algorithm won't be able to directly take in those features as inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Y3iRGkJkVkol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "B-qgANejVkon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7L5ynf7gVkon",
        "colab_type": "text"
      },
      "source": [
        "## Feature hashing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "z_qalMqzVkoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction import FeatureHasher\n",
        "fh = FeatureHasher(n_features=8, input_type='string')\n",
        "sp = fh.fit_transform(train['ord_5'])\n",
        "df = pd.DataFrame(sp.toarray(), columns=['fh1', 'fh2', 'fh3', 'fh4', 'fh5', 'fh6', 'fh7', 'fh8'])\n",
        "pd.concat([train, df], axis=1)\n",
        "train.drop('ord_5',axis=1,inplace=True)\n",
        "train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8PaWrgUfVkop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction import FeatureHasher\n",
        "fh = FeatureHasher(n_features=8, input_type='string')\n",
        "sp = fh.fit_transform(test['ord_5'])\n",
        "df = pd.DataFrame(sp.toarray(), columns=['fh1', 'fh2', 'fh3', 'fh4', 'fh5', 'fh6', 'fh7', 'fh8'])\n",
        "pd.concat([test, df], axis=1)\n",
        "test.drop('ord_5',axis=1,inplace=True)\n",
        "test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeH3FcImVkop",
        "colab_type": "text"
      },
      "source": [
        "## One-hot coding for nomial features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "z8YhMDYIVkoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.get_dummies(train, columns=['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4','ord_3', 'ord_4'],drop_first=True, sparse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ekhK2tZfVkou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PDNauJZsVkov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.get_dummies(test, columns=['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4','ord_3', 'ord_4'],drop_first=True, sparse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "96_QdfiZVkow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOcqSnbsVkox",
        "colab_type": "text"
      },
      "source": [
        "## Target encoder\n",
        "Target-based encoding is numerization of categorical variables via target. In this method, we replace the categorical variable with just one new numerical variable and replace each category of the categorical variable with its corresponding probability of the target (if categorical) or average of the target (if numerical). The main drawbacks of this method are its dependency to the distribution of the target, and its lower predictability power compare to the binary encoding method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oGmOIczLVkox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols_ = ['nom_5','nom_6','nom_7','nom_8','nom_9']\n",
        "ce_target_encoder = ce.TargetEncoder(cols = cols_, smoothing=0.50)\n",
        "ce_target_encoder.fit(train[cols_], train['target'])\n",
        "train_nom = ce_target_encoder.transform(train[cols_])\n",
        "train.drop(['nom_5','nom_6','nom_7','nom_8','nom_9'],axis=1,inplace=True)\n",
        "train = pd.concat([train, train_nom], axis=1)\n",
        "train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yrRST-bgVkoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # https://gist.github.com/marnixkoops/e68815d30474786e2b293682ed7cdb01\n",
        "# def target_encoder(df, column, target, index=None, method='mean'):\n",
        "#     \"\"\"\n",
        "#     Target-based encoding is numerization of a categorical variables via the target variable. Main purpose is to deal\n",
        "#     with high cardinality categorical features without exploding dimensionality. This replaces the categorical variable\n",
        "#     with just one new numerical variable. Each category or level of the categorical variable is represented by a\n",
        "#     summary statistic of the target for that level.\n",
        "#     Args:\n",
        "#         df (pandas df): Pandas DataFrame containing the categorical column and target.\n",
        "#         column (str): Categorical variable column to be encoded.\n",
        "#         target (str): Target on which to encode.\n",
        "#         index (arr): Can be supplied to use targets only from the train index. Avoids data leakage from the test fold\n",
        "#         method (str): Summary statistic of the target. Mean, median or std. deviation.\n",
        "#     Returns:\n",
        "#         arr: Encoded categorical column.\n",
        "#     \"\"\"\n",
        "\n",
        "#     index = df.index if index is None else index # Encode the entire input df if no specific indices is supplied\n",
        "\n",
        "#     if method == 'mean':\n",
        "#         encoded_column = df[column].map(df.iloc[index].groupby(column)[target].mean())\n",
        "#     elif method == 'median':\n",
        "#         encoded_column = df[column].map(df.iloc[index].groupby(column)[target].median())\n",
        "#     elif method == 'std':\n",
        "#         encoded_column = df[column].map(df.iloc[index].groupby(column)[target].std())\n",
        "#     else:\n",
        "#         raise ValueError(\"Incorrect method supplied: '{}'. Must be one of 'mean', 'median', 'std'\".format(method))\n",
        "\n",
        "#     return encoded_column\n",
        "\n",
        "# train['nom_5'] = target_encoder(train, column='nom_5', target='target', method='mean')\n",
        "# train['nom_6'] = target_encoder(train, column='nom_6', target='target', method='mean')\n",
        "# train['nom_7'] = target_encoder(train, column='nom_6', target='target', method='mean')\n",
        "# train['nom_8'] = target_encoder(train, column='nom_6', target='target', method='mean')\n",
        "# train['nom_9'] = target_encoder(train, column='nom_6', target='target', method='mean')\n",
        "\n",
        "# train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZYkwWt1XVkoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ce_target_encoder = ce.TargetEncoder(cols = ['nom_5','nom_6','nom_7','nom_8','nom_9'], smoothing=0.50)\n",
        "cols = ['nom_5','nom_6','nom_7','nom_8','nom_9']\n",
        "ce_target_encoder.fit(train[cols], train['target'])\n",
        "#train = oof.sort_index() \n",
        "test_nom = ce_target_encoder.transform(test[cols])\n",
        "test_nom"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DTZhrcO8Vko0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.drop(['nom_5','nom_6','nom_7','nom_8','nom_9'],axis=1,inplace=True)\n",
        "test = pd.concat([test, test_nom], axis=1)\n",
        "test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-ucgNekVko1",
        "colab_type": "text"
      },
      "source": [
        "## Label-encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5TCJRdIvVko2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6o3is41gVko2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Category variables -> Numerical variables\n",
        "list_feat=['bin_3','bin_4','ord_1','ord_2']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dUgq7w8hVko3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for feature in list_feat:\n",
        "    labels = train[feature].astype('category').cat.categories.tolist()\n",
        "    replace_map_comp = {feature : {k: v for k,v in zip(labels,list(range(0,len(labels)+1)))}}\n",
        "\n",
        "    train.replace(replace_map_comp, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kwVkikZyVko4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_feat=['bin_3','bin_4','ord_1','ord_2']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "S-A074MRVko4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for feature in list_feat:\n",
        "    labels = test[feature].astype('category').cat.categories.tolist()\n",
        "    replace_map_comp = {feature : {k: v for k,v in zip(labels,list(range(0,len(labels)+1)))}}\n",
        "\n",
        "    test.replace(replace_map_comp, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-CquvRsVko5",
        "colab_type": "text"
      },
      "source": [
        "## Handling cyclical features: Day, month"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gdRCovhVVko5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Day\n",
        "train['day_sin'] = np.sin(2 * np.pi * train['day']/7)\n",
        "train['day_cos'] = np.cos(2 * np.pi * train['day']/7)\n",
        "# Month\n",
        "train['month_sin'] = np.sin(2 * np.pi * train['month']/12)\n",
        "train['month_cos'] = np.cos(2 * np.pi * train['month']/12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Mohhn3mSVko6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Day\n",
        "test['day_sin'] = np.sin(2 * np.pi * test['day']/7)\n",
        "test['day_cos'] = np.cos(2 * np.pi * test['day']/7)\n",
        "# Month\n",
        "test['month_sin'] = np.sin(2 * np.pi * test['month']/12)\n",
        "test['month_cos'] = np.cos(2 * np.pi * test['month']/12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Xnclr8nJVko7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Vt21sc-jVko8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sY7J-rocVko9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.drop(['day','month'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gJuOVCMoVko-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.drop(['day','month'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tEOm4tvuVko-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "728gLXRvVko_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_target = train['target']\n",
        "# train_target\n",
        "# train.drop('target',axis=1,inplace=True)\n",
        "# train = pd.concat([train, train_target], axis=1)\n",
        "# train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "P8tQWZ8aVkpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "A9v0csIqVkpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checking the imbalance\n",
        "sb.countplot(x='target',data=train,palette='RdBu_r') # Barplot for the dependent variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Zp5-1F6ZVkpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['target'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EioVZ9m2VkpB",
        "colab_type": "text"
      },
      "source": [
        "# Oversampling\n",
        "A widely adopted technique for dealing with highly unbalanced datasets is called resampling. It consists of removing samples from the majority class (under-sampling) and / or adding more examples from the minority class (over-sampling).\n",
        "Despite the advantage of balancing classes, these techniques also have their weaknesses (there is no free lunch). The simplest implementation of over-sampling is to duplicate random records from the minority class, which can cause overfitting. In under-sampling, the simplest technique involves removing random records from the majority class, which can cause loss of information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FWWZqodgVkpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Separate the majority of data and the minority of data\n",
        "df_majority = train[train['target']==0]\n",
        "df_minority = train[train['target']==1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "M_GFTQZ0VkpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# oversampling minority data\n",
        "df_minority_upsampled = resample(df_minority, \n",
        "                                 replace=True,     # replace the original data\n",
        "                                 n_samples=208236,    # the number of data to match with majority\n",
        "                                 random_state=123) # reproducible results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5OTxrD_vVkpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine majority class with upsampled minority class\n",
        "df_upsampled = pd.concat([df_majority, df_minority_upsampled])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hCbysHc3VkpE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sb.countplot(x='target',data=df_upsampled,palette='RdBu_r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OhDyPlraVkpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display new class counts\n",
        "df_upsampled['target'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooIM9A4vVkpH",
        "colab_type": "text"
      },
      "source": [
        "As you can see, the new DataFrame has more observations than the original, and the ratio of the two classes is now 1:1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iwFkWBKIVkpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset=df_upsampled._get_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "r7ERwb1bVkpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separate input features (X) and target variable (y)\n",
        "y = df_upsampled.target\n",
        "X = df_upsampled.drop('target', axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hInHdyL9VkpI",
        "colab_type": "text"
      },
      "source": [
        "# Feature Importance\n",
        "\n",
        "We can get the feature importance of each feature of our dataset by using the feature importance property of the model. Feature importance gives you a score for each feature of our data, the higher the score more important or relevant is the feature towards our output variable. Feature importance is an inbuilt class that comes with Tree Based Classifiers, we will be using Extra Tree Classifier for extracting the top 10 features for the dataset.<br>\n",
        "\n",
        "There are 4 different feature selection techniques: univariate selection, recursive feature elimination, principle component analysis, and feature importance. So, we need to select the important features: Extra Trees Classifier and XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "81HrOEkVVkpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AtAWCqMzVkpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Build a forest and compute the feature importances\n",
        "# model1 = ExtraTreesClassifier(n_estimators=250,\n",
        "#                               random_state=0)\n",
        "\n",
        "# model1.fit(dataset_train,dataset_label)\n",
        "# importances = model1.feature_importances_\n",
        "# std = np.std([tree.feature_importances_ for tree in model1.estimators_],\n",
        "#              axis=0)\n",
        "# indices = np.argsort(importances)[::-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wkRc_UBcVkpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unbalanced dataset\n",
        "# X = train.iloc[:,np.r_[:,0:8,9:76]]  #independent columns\n",
        "# y = train.iloc[:,np.r_[:,8]]    #target column\n",
        "# Balanced dataset\n",
        "y = df_upsampled.target\n",
        "X = df_upsampled.drop('target', axis=1)\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "model1 = ExtraTreesClassifier()\n",
        "model1.fit(X,y)\n",
        "print(model1.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "#plot graph of feature importances for better visualization\n",
        "feat_importances = pd.Series(model1.feature_importances_, index=X.columns)\n",
        "feat_importances.nlargest(20).plot(kind='barh')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcWHUFrFVkpK",
        "colab_type": "text"
      },
      "source": [
        "# Correlation Matrix with Heatmap\n",
        "\n",
        "Correlation states how the features are related to each other or the target variable. Correlation can be positive (increase in one value of feature increases the value of the target variable) or negative (increase in one value of feature decreases the value of the target variable) Heatmap makes it easy to identify which features are most related to the target variable, we will plot heatmap of correlated features using the seaborn library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EuD-9ZWuVkpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X = dataset[:,np.r_[:,0:8,9:76]]   #independent columns\n",
        "# y = dataset[:,np.r_[:,8]]    #target column\n",
        "y = df_upsampled.target\n",
        "X = df_upsampled.drop('target', axis=1)\n",
        "#get correlations of each features in dataset\n",
        "corrmat = train.corr()\n",
        "top_corr_features = corrmat.index\n",
        "plt.figure(figsize=(20,20))\n",
        "#plot heat map\n",
        "g=sb.heatmap(train[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "On2yCWXzVkpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from xgboost import XGBClassifier\n",
        "# from xgboost import plot_importance\n",
        "\n",
        "# # X = dataset[:,np.r_[:,0:8,9:76]]   #independent columns\n",
        "# # y = dataset[:,np.r_[:,8]]    #target column\n",
        "# y = df_upsampled.target\n",
        "# X = df_upsampled.drop('target', axis=1)\n",
        "# # fit model no training data\n",
        "# model2 = XGBClassifier()\n",
        "# model2.fit(X,y)\n",
        "# # feature importance\n",
        "# print(model2.feature_importances_)\n",
        "# # plot feature importance\n",
        "\n",
        "# plt.figure(figsize=(3,6))\n",
        "# plot_importance(model2,max_num_features=20)\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xeWTNfxUVkpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from numpy import sort\n",
        "# from xgboost import XGBClassifier\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# # X = train.iloc[:,np.r_[:,0:8,9:76]]  #independent columns\n",
        "# # Y = train.iloc[:,np.r_[:,8]]    #target column\n",
        "# y = df_upsampled.target\n",
        "# X = df_upsampled.drop('target', axis=1)\n",
        "\n",
        "# # split data into train and test sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "# # fit model on all training data\n",
        "# model = XGBClassifier()\n",
        "# model.fit(X_train, y_train)\n",
        "# # make predictions for test data and evaluate\n",
        "# y_pred = model.predict(X_test)\n",
        "# predictions = [round(value) for value in y_pred]\n",
        "# accuracy = accuracy_score(y_test, predictions)\n",
        "# print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "# # Fit model using each importance as a threshold\n",
        "# thresholds = sort(model.feature_importances_)\n",
        "# for thresh in thresholds:\n",
        "#     # select features using threshold\n",
        "#     selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
        "#     select_X_train = selection.transform(X_train)\n",
        "#     # train model\n",
        "#     selection_model = XGBClassifier()\n",
        "#     selection_model.fit(select_X_train, y_train)\n",
        "#     # eval model\n",
        "#     select_X_test = selection.transform(X_test)\n",
        "#     y_pred = selection_model.predict(select_X_test)\n",
        "#     predictions = [round(value) for value in y_pred]\n",
        "#     accuracy = accuracy_score(y_test, predictions)\n",
        "#     print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3KGTHH6sVkpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Import the random forest model.\n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "## This line instantiates the model. \n",
        "model3 = RandomForestClassifier() \n",
        "## Fit the model on your training data.\n",
        "model3.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "J_l1S2nOVkpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_importances = pd.DataFrame(model3.feature_importances_,\n",
        "                                   index = X.columns,\n",
        "                                    columns=['importance']).sort_values('importance',ascending=False)\n",
        "feature_importances"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1EIlIsvkVkpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(pd.Series(model3.feature_importances_, index=X.columns).nlargest(20).plot(kind='barh'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "h0Vv0jRBVkpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display the relative importance of each attribute\n",
        "output1=model1.feature_importances_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WIqPS50cVkpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# output2=model2.feature_importances_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FpoP9U6lVkpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output3=model3.feature_importances_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gZMLMcdRVkpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = output1 + output3 #  + output2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-Jzd5Ih9VkpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n=13\n",
        "important_features=np.argsort(output)[::-1][:n]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZrZO3vwtVkpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "important_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JjlOsdIgVkpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data = X.iloc[:,important_features]\n",
        "training_label = y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1n7NDLxgVkpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing_data=test.iloc[:,important_features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af2glbLvVkpV",
        "colab_type": "text"
      },
      "source": [
        "# Methology"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LDP0c49gVkpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "f6UrjL1JVkpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training_data = train.iloc[:,np.r_[:,0:8,9:76]]  #independent columns\n",
        "# training_label = train.iloc[:,np.r_[:,8]]   #target column\n",
        "training_label = df_upsampled.target\n",
        "training_data = df_upsampled.drop('target', axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwGKb-SpVkpW",
        "colab_type": "text"
      },
      "source": [
        "# 1. Building a Logistic Regression model\n",
        "Let's build our model using LogisticRegression from Scikit-learn package. This function implements logistic regression and can use different numerical optimizers to find parameters, including ‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’ solvers. You can find extensive information about the pros and cons of these optimizers if you search it in internet.\n",
        "The version of Logistic Regression in Scikit-learn, support regularization. Regularization is a technique used to solve the overfitting problem in machine learning models. C parameter indicates inverse of regularization strength which must be a positive float. Smaller values specify stronger regularization. Now lets fit our model with train set:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP1xnm7dVkpW",
        "colab_type": "text"
      },
      "source": [
        "## Train Test Split\n",
        "Let's start by splitting our data into a training set and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Kfcvz1BMVkpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(training_data,training_label,test_size=0.33,random_state=101)\n",
        "print ('Train set:', X_train.shape,  y_train.shape)\n",
        "print ('Test set:', X_test.shape,  y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH7vZFIPVkpX",
        "colab_type": "text"
      },
      "source": [
        "## Training and Predicting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "flsEvKKiVkpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logmodel = LogisticRegression(C=0.01, solver='liblinear')\n",
        "logmodel.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "s-HiCtBQVkpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = logmodel.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjC4LuuAVkpY",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation\n",
        "### confusion matrix\n",
        "Another way of looking at accuracy of classifier is to look at __confusion matrix__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GomwrKpbVkpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Accuracy is\", accuracy_score(y_test,predictions)*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BfJ0Tbr7VkpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm1 = confusion_matrix(y_test,predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ipDYciVWVkpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(cm1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2a0in-LfVkpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zrs-uVs9Vkpc",
        "colab_type": "text"
      },
      "source": [
        "Based on the count of each section, we can calculate precision and recall of each label:\n",
        "\n",
        "\n",
        "- __Precision__ is a measure of the accuracy provided that a class label has been predicted. It is defined by: precision = TP / (TP + FP)\n",
        "\n",
        "- __Recall__ is true positive rate. It is defined as: Recall =  TP / (TP + FN)\n",
        "\n",
        "    \n",
        "So, we can calculate precision and recall of each class.\n",
        "\n",
        "__F1 score:__\n",
        "Now we are in the position to calculate the F1 scores for each label based on the precision and recall of that label. \n",
        "\n",
        "The F1 score is the harmonic average of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0. It is a good way to show that a classifer has a good value for both recall and precision.\n",
        "\n",
        "\n",
        "And finally, we can tell the average accuracy for this classifier is the average of the F1-score for both labels, which is 0.72 in our case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KKqPpvfIVkpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.clf()\n",
        "plt.imshow(cm1, interpolation='nearest', cmap=plt.cm.Wistia)\n",
        "classNames = ['Negative','Positive']\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "tick_marks = np.arange(len(classNames))\n",
        "plt.xticks(tick_marks, classNames, rotation=45)\n",
        "plt.yticks(tick_marks, classNames)\n",
        "s = [['TN','FP'], ['FN', 'TP']]\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm1[i][j]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qMzJhg0Vkpc",
        "colab_type": "text"
      },
      "source": [
        "## 2. Building a K Nearest Neighbors model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMCMJ1WIVkpc",
        "colab_type": "text"
      },
      "source": [
        "### Standardize the Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Fo4zToBKVkpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scaler = StandardScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZxRPEZ14Vkpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scaler.fit(training_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bXHQL3m3Vkpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scaled_features = scaler.transform(training_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TOYZ6VzaVkpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scaled_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE0W8-8tVkpf",
        "colab_type": "text"
      },
      "source": [
        "### Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "B_heOa-4Vkpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(scaled_features,training_label,test_size=0.30)\n",
        "# print ('Train set:', X_train.shape,  y_train.shape)\n",
        "# print ('Test set:', X_test.shape,  y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCHHW4m8Vkpg",
        "colab_type": "text"
      },
      "source": [
        "### Choosing a K Value\n",
        "Use the elbow method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pBTKg5K6Vkpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# error_rate = []\n",
        "\n",
        "# # Will take some time\n",
        "# for i in range(1,20):\n",
        "    \n",
        "#     knn = KNeighborsClassifier(n_neighbors=i)\n",
        "#     knn.fit(X_train,y_train)\n",
        "#     pred_i = knn.predict(X_test)\n",
        "#     error_rate.append(np.mean(pred_i != y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-RTtT_jVkph",
        "colab_type": "text"
      },
      "source": [
        "### Using KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_BKvkc7GVkph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# knn = KNeighborsClassifier(n_neighbors=1) # n_neighbors = k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "39G3r-K6Vkph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# knn.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "r-gWcgX6Vkpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predictions = knn.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vo4MpnlVkpi",
        "colab_type": "text"
      },
      "source": [
        "### Predictions and Evaluations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_9mCI-t3Vkpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn import metrics\n",
        "# print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, knn.predict(X_train)))\n",
        "# print(\"Test set Accuracy: \", metrics.accuracy_score(y_test, predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xSJXtl48Vkpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"Accuracy is\", accuracy_score(y_test,predictions)*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PrFbyMHgVkpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cm2 = confusion_matrix(y_test,predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Fv6I9INjVkpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(cm2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "evt59Gr4Vkpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(classification_report(y_test,predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "p48YWT6pVkpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.clf()\n",
        "# plt.imshow(cm2, interpolation='nearest', cmap=plt.cm.Wistia)\n",
        "# classNames = ['Negative','Positive']\n",
        "# plt.title('Confusion Matrix')\n",
        "# plt.ylabel('True label')\n",
        "# plt.xlabel('Predicted label')\n",
        "# tick_marks = np.arange(len(classNames))\n",
        "# plt.xticks(tick_marks, classNames, rotation=45)\n",
        "# plt.yticks(tick_marks, classNames)\n",
        "# s = [['TN','FP'], ['FN', 'TP']]\n",
        "# for i in range(2):\n",
        "#     for j in range(2):\n",
        "#         plt.text(j,i, str(s[i][j])+\" = \"+str(cm2[i][j]))\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81TQXR1sVkpl",
        "colab_type": "text"
      },
      "source": [
        "## 3. Building the Decision Tree\n",
        "We'll start just by training a single decision tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "J38ltY90Vkpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(training_data,training_label,test_size=0.3,random_state=101)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TP1wzJBHVkpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtree = DecisionTreeClassifier(criterion='entropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xHTIGayEVkpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtree.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8nCx2EF-Vkpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = dtree.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQafBikSVkpn",
        "colab_type": "text"
      },
      "source": [
        "## Prediction and Evaluation\n",
        "Let's evaluate our decision tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nnh22d_OVkpn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Accuracy is\", accuracy_score(y_test,predictions)*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "plm2ud6DVkpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jtd8JYiuVkpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm3 = confusion_matrix(y_test,predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aXHbr3S_Vkpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(cm3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8Pa1eLPkVkpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.clf()\n",
        "plt.imshow(cm3, interpolation='nearest', cmap=plt.cm.Wistia)\n",
        "classNames = ['Negative','Positive']\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "tick_marks = np.arange(len(classNames))\n",
        "plt.xticks(tick_marks, classNames, rotation=45)\n",
        "plt.yticks(tick_marks, classNames)\n",
        "s = [['TN','FP'], ['FN', 'TP']]\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm3[i][j]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB2CoSLWVkpr",
        "colab_type": "text"
      },
      "source": [
        "## 4. Building the Random Forests model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JLHbZgpiVkpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rfc = RandomForestClassifier(n_estimators=150)\n",
        "rfc.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UHXCAruSVkps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rfc_pred = rfc.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KhI-7RyuVkps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Accuracy is\", accuracy_score(y_test,rfc_pred)*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nw9W8kYeVkps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Accuracy is\", accuracy_score(y_test,rfc_pred)*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RoJy0fTLVkpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_test,rfc_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FphgbvQaVkpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm4 = confusion_matrix(y_test,rfc_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KY0y6eHYVkpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(cm4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Qqm_3FNRVkpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.clf()\n",
        "plt.imshow(cm4, interpolation='nearest', cmap=plt.cm.Wistia)\n",
        "classNames = ['Negative','Positive']\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "tick_marks = np.arange(len(classNames))\n",
        "plt.xticks(tick_marks, classNames, rotation=45)\n",
        "plt.yticks(tick_marks, classNames)\n",
        "s = [['TN','FP'], ['FN', 'TP']]\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm4[i][j]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8xawbNiVkpy",
        "colab_type": "text"
      },
      "source": [
        "## 5. Building the Support Vector Machines model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q_UlwRUVkpz",
        "colab_type": "text"
      },
      "source": [
        "### Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "abaHEPgMVkpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(training_data, training_label, test_size=0.30, random_state=101)\n",
        "# print ('Train set:', X_train.shape,  y_train.shape)\n",
        "# print ('Test set:', X_test.shape,  y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RpUUfnaSVkpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = SVC()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA-rAR7TVkp0",
        "colab_type": "text"
      },
      "source": [
        "The SVM algorithm offers a choice of kernel functions for performing its processing. Basically, mapping data into a higher dimensional space is called kernelling. The mathematical function used for the transformation is known as the kernel function, and can be of different types, such as:\n",
        "\n",
        "    1.Linear\n",
        "    2.Polynomial\n",
        "    3.Radial basis function (RBF)\n",
        "    4.Sigmoid\n",
        "Each of these functions has its characteristics, its pros and cons, and its equation, but as there's no easy way of knowing which function performs best with any given dataset, we usually choose different functions in turn and compare the results. Let's just use the default, RBF (Radial Basis Function) for this lab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ORTclds5Vkp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.fit(X_train,y_train) # If C is 0, we can have no margin kernel ='Radial Basis Functions'(Big cone located in all points of data set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1nr11oQVkp1",
        "colab_type": "text"
      },
      "source": [
        "### Predictions and Evaluations\n",
        "Now let's predict using the trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "p2szXyXGVkp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predictions = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zGBKTREjVkp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cm5 = confusion_matrix(y_test,predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VsSHedvpVkp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"Accuracy is\", accuracy_score(y_test,predictions)*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9E0b8Yb-Vkp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(cm5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bsr3J-mcVkp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(classification_report(y_test,predictions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CAJOtw3pVkp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.clf()\n",
        "# plt.imshow(cm5, interpolation='nearest', cmap=plt.cm.Wistia)\n",
        "# classNames = ['Negative','Positive']\n",
        "# plt.title('Confusion Matrix')\n",
        "# plt.ylabel('True label')\n",
        "# plt.xlabel('Predicted label')\n",
        "# tick_marks = np.arange(len(classNames))\n",
        "# plt.xticks(tick_marks, classNames, rotation=45)\n",
        "# plt.yticks(tick_marks, classNames)\n",
        "# s = [['TN','FP'], ['FN', 'TP']]\n",
        "# for i in range(2):\n",
        "#     for j in range(2):\n",
        "#         plt.text(j,i, str(s[i][j])+\" = \"+str(cm5[i][j]))\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjHbtLvkVkp3",
        "colab_type": "text"
      },
      "source": [
        "# Submission "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TS2v0ZmMVkp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.read_csv('../input/cat-in-the-dat/sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QGESW99KVkp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_prediction=rfc.predict(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Fso9cGQPVkp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission[\"target\"] = rfc.predict_proba(test)[:, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cLW8qYKiVkp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# submission[\"target\"] =final_prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wMN319bhVkp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ia9OZpHyVkp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}